{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare each step of convert_photometry.py to 'phot_to_dframes_breakdown.ipynb' to match outputs for .nwb conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legend: \n",
    "\n",
    "cp = convert_photometry\n",
    "\n",
    "lv = LabView_photometry_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = scipy.io.loadmat('T:/ACh Rats/80B8CE6_ceecee/02222024-L/signals.mat',matlab_compatible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_ref = signals[\"ref\"]\n",
    "cp_sig1 = signals[\"sig1\"]\n",
    "cp_sig2 = signals[\"sig2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_ref = signals[\"ref\"]\n",
    "lv_sig1 = signals[\"sig1\"]\n",
    "lv_sig2 = signals[\"sig2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 10000  # sampling rate of photometry system\n",
    "Fs = 250  # downsample frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP\n",
    "cp_green = cp_sig1[0][:: int(SR / Fs)]\n",
    "cp_reference = cp_ref[0][:: int(SR / Fs)]\n",
    "cp_red = cp_sig2[0][:: int(SR / Fs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabView\n",
    "lv_green = lv_sig1[0][:: int(SR / Fs)]\n",
    "lv_reference = lv_ref[0][:: int(SR / Fs)]\n",
    "lv_red = lv_sig2[0][:: int(SR / Fs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downsampling, CP data gets converted to pd.Series while LV data gets converted to a DataFrame then each column is saved as a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert raw signals to Pandas Series for rolling mean\n",
    "cp_raw_green = pd.Series(cp_green)\n",
    "cp_raw_reference = pd.Series(cp_reference)\n",
    "cp_raw_red = pd.Series(cp_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_sigs = pd.DataFrame()\n",
    "lv_sigs['ref'] = lv_reference\n",
    "lv_sigs['green'] = lv_green\n",
    "lv_sigs['red'] = lv_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_raw_reference = lv_sigs['ref']\n",
    "lv_raw_green = lv_sigs['green']\n",
    "lv_raw_red = lv_sigs['red']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_window = int(Fs / 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_reference = np.array(cp_raw_reference.rolling(window=smooth_window, min_periods=1).mean()).reshape(len(cp_raw_reference), 1)\n",
    "cp_signal_green = np.array(cp_raw_green.rolling(window=smooth_window, min_periods=1).mean()).reshape(len(cp_raw_green), 1)\n",
    "cp_signal_red = np.array(cp_raw_red.rolling(window=smooth_window, min_periods=1).mean()).reshape(len(cp_raw_red), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_reference = np.array(lv_raw_reference.rolling(window=smooth_window, min_periods=1).mean()).reshape(len(lv_raw_reference), 1)\n",
    "lv_signal_green = np.array(lv_raw_green.rolling(window=smooth_window, min_periods=1).mean()).reshape(len(lv_raw_green), 1)\n",
    "lv_signal_red = np.array(lv_raw_red.rolling(window=smooth_window, min_periods=1).mean()).reshape(len(lv_raw_red), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the outputs match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_reference, lv_reference)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_signal_green, lv_signal_green)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_signal_red, lv_signal_red)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*, block=None)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(cp_signal_green)\n",
    "plt.plot(lv_signal_green)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, everything is the same after calculating the rolling average of our signals. Moving on to baseline correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cp_WhittakerSmooth(data, binary_mask, lambda_):\n",
    "    \"\"\"\n",
    "    Penalized least squares algorithm for background fitting\n",
    "\n",
    "    Wittaker smoothing is a method for fitting a smooth background to noisy data, often used in signal processing to remove baseline noise or trends while preserving the main features of the signal.\n",
    "\n",
    "    - fits a smooth background to the input data ('data') by minimizaing the sum of squared differences between the data and the background.\n",
    "    - uses a binary mask ('binary_mask') to identify the signal regions in the data (peaks and troughs) that are not part of the background calculation.\n",
    "    - uses a penalty term ('lambda_') to control the smoothness of the background. Discourages rapid changes and enforces smoothness.\n",
    "\n",
    "    input\n",
    "        data: input data. 1D array that represents the signal data.\n",
    "        binary_mask: binary mask that defines which points are signals (peaks) and which are background. 0 = Peak / 1 = Background\n",
    "        lambda_: parameter that can be adjusted by user. The larger lambda is, the smoother the resulting background. Careful: too large can lead to over smoothing.\n",
    "    output\n",
    "        the fitted background vector\n",
    "    \"\"\"\n",
    "    data_matrix = np.matrix(data)  # matrix structure of data in order to use matrix operations\n",
    "    data_size = data_matrix.size  # size of the data matrix\n",
    "    ID_matrix = eye(\n",
    "        data_size, format=\"csc\"\n",
    "    )  # creates an identity matrix the size of data_size in compressed sparse column (csc) format\n",
    "    diff_matrix = ID_matrix[1:] - ID_matrix[:-1]  # numpy.diff() does not work with sparse matrix. This is a workaround.\n",
    "    diagonal_matrix = diags(\n",
    "        binary_mask, 0, shape=(data_size, data_size)\n",
    "    )  # creates a diagonal matrix with the binary mask values on the diagonal\n",
    "    A = csc_matrix(\n",
    "        diagonal_matrix + (lambda_ * diff_matrix.T * diff_matrix)\n",
    "    )  # represents the combination of the diagonal matrix and the smoothness penalty term Lambda_\n",
    "    B = csc_matrix(diagonal_matrix * data_matrix.T)  # represents the weighted data\n",
    "    smoothed_baseline = spsolve(A, B)  # solves the linear system of equations to find the smoothed baseline\n",
    "\n",
    "    return np.array(smoothed_baseline)\n",
    "\n",
    "\n",
    "def cp_airPLS(data, lambda_=100, max_iterations=15):\n",
    "    \"\"\"\n",
    "    Adaptive iteratively reweighted penalized least squares for baseline fitting\n",
    "    DOI : 10.1039/b922045c\n",
    "\n",
    "    This function is used to fit a baseline to the input data x using adaptive iteratively reweighted penalized least squares.\n",
    "    The baseline is fitted by minimizing the weighted sum of the squared differences between the input data and the baseline.\n",
    "    The function uses a penalized least squares approach to fit the baseline, with a penalty term that encourages smoothness.\n",
    "    The function iteratively adjusts the weights and the baseline until convergence is achieved.\n",
    "\n",
    "    input\n",
    "        data: input data (i.e. chromatogram of spectrum)\n",
    "        lambd: Parameter that can be adjusted by user. The larger lambda is, the smoother the resulting baseline.\n",
    "        max_iterations: Maximum number of iterations for the algorithm to adjust the weights and fit the baseline.\n",
    "\n",
    "    output\n",
    "        the fitted baseline vector\n",
    "    \"\"\"\n",
    "\n",
    "    data_points = data.shape[0]  # number of data points\n",
    "    weights = np.ones(data_points)  # initial weights set to 1. All points are initially treated equally.\n",
    "\n",
    "    for i in range(1, max_iterations + 1):\n",
    "        # loop runs 'max_iterations' times to adjust the weights and fit the baseline\n",
    "        baseline = cp_WhittakerSmooth(\n",
    "            data=data, binary_mask=weights, lambda_=lambda_,\n",
    "        )  \n",
    "        delta = (\n",
    "            data - baseline\n",
    "        )  # difference between data and baseline to calculate residuals, how much each data point deviates from the baseline. delta > 0 == peak. delta < 0 == background.\n",
    "        sum_of_neg_deltas = np.abs(delta[delta < 0].sum())  # how much data is below the baseline.\n",
    "\n",
    "        if (\n",
    "            sum_of_neg_deltas < 0.001 * (abs(data)).sum() or i == max_iterations\n",
    "        ):  # convergence check: if sum_of_neg_deltas is less than 0.001 of the total data, or if the maximum number of iterations is reached, the loop breaks.\n",
    "            if i == max_iterations:\n",
    "                print(\"WARING max iteration reached!\")\n",
    "            break\n",
    "\n",
    "        weights[delta >= 0] = (\n",
    "            0  # delta >= 0 means that this point is part of a peak, so its weight is set to 0 in order to ignore it\n",
    "        )\n",
    "        weights[delta < 0] = np.exp(\n",
    "            i * np.abs(delta[delta < 0]) / sum_of_neg_deltas\n",
    "        )  # updates the weights for the negative deltas. Gives more weight to larger residuals using an exponential function.\n",
    "        weights[0] = np.exp(\n",
    "            i * (delta[delta < 0]).max() / sum_of_neg_deltas\n",
    "        )  # updates the weights for the first and last data points to ensure edges of data are not ignored or underweighed.\n",
    "        weights[-1] = weights[0]\n",
    "    return baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find baseline for sig and ref\n",
    "\n",
    "from scipy.sparse import csc_matrix, eye, diags\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "def lv_WhittakerSmooth(x,w,lambda_,differences=1):\n",
    "    '''\n",
    "    Penalized least squares algorithm for background fitting\n",
    "    \n",
    "    input\n",
    "        x: input data (i.e. chromatogram of spectrum)\n",
    "        w: binary masks (value of the mask is zero if a point belongs to peaks and one otherwise)\n",
    "        lambda_: parameter that can be adjusted by user. The larger lambda is,  the smoother the resulting background\n",
    "        differences: integer indicating the order of the difference of penalties\n",
    "    \n",
    "    output\n",
    "        the fitted background vector\n",
    "    '''\n",
    "    X=np.matrix(x)\n",
    "    m=X.size\n",
    "    i=np.arange(0,m)\n",
    "    E=eye(m,format='csc')\n",
    "    D=E[1:]-E[:-1] # numpy.diff() does not work with sparse matrix. This is a workaround.\n",
    "    W=diags(w,0,shape=(m,m))\n",
    "    A=csc_matrix(W+(lambda_*D.T*D))\n",
    "    B=csc_matrix(W*X.T)\n",
    "    background=spsolve(A,B)\n",
    "    return np.array(background)\n",
    "\n",
    "def lv_airPLS(x, lambda_=100, porder=1, itermax=15):\n",
    "    '''\n",
    "    Adaptive iteratively reweighted penalized least squares for baseline fitting\n",
    "    \n",
    "    input\n",
    "        x: input data (i.e. chromatogram of spectrum)\n",
    "        lambda_: parameter that can be adjusted by user. The larger lambda is,  the smoother the resulting background, z\n",
    "        porder: adaptive iteratively reweighted penalized least squares for baseline fitting\n",
    "    \n",
    "    output\n",
    "        the fitted background vector\n",
    "    '''\n",
    "    m=x.shape[0]\n",
    "    w=np.ones(m)\n",
    "    for i in range(1,itermax+1):\n",
    "        z=lv_WhittakerSmooth(x,w,lambda_, porder)\n",
    "        d=x-z\n",
    "        dssn=np.abs(d[d<0].sum())\n",
    "        if(dssn<0.001*(abs(x)).sum() or i==itermax):\n",
    "            if(i==itermax): print('WARING max iteration reached!')\n",
    "            break\n",
    "        w[d>=0]=0 # d>0 means that this point is part of a peak, so its weight is set to 0 in order to ignore it\n",
    "        w[d<0]=np.exp(i*np.abs(d[d<0])/dssn)\n",
    "        w[0]=np.exp(i*(d[d<0]).max()/dssn) \n",
    "        w[-1]=w[0]\n",
    "    return z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd = 1e8\n",
    "max_iterations = 50\n",
    "# smoothed background lines\n",
    "cp_ref_base = cp_airPLS(cp_raw_reference.T, lambda_=lambd, max_iterations=max_iterations).reshape(len(cp_raw_reference), 1)\n",
    "cp_g_base = cp_airPLS(cp_raw_green.T, lambda_=lambd,  max_iterations=max_iterations).reshape(len(cp_raw_green), 1)\n",
    "cp_r_base = cp_airPLS(cp_raw_red.T, lambda_=lambd, max_iterations=max_iterations).reshape(len(cp_raw_red), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd = 1e8\n",
    "porder = 1\n",
    "itermax = 50\n",
    "# airPLS Basleine is calculated for photobleaching correction. \n",
    "# The baseline represents a drift in the signal (downward decay of fluorescence over time) that is alter used to straighten the signal for clarity. \n",
    "# This drift/baseline is identified using a penalized least squares approach\n",
    "# Minimizes the sum of the squared differences between the observed data and the baseline model and introduces a penalty for the wigglyness of the baseline controlled by the lambda parameter. Larger lambda, more smooth\n",
    "# Additionally, data points are weighted and refined iteratively where the further they are from the baseline (e.g. a sharp peak), the less weight is given in order to focus more on baseline points \n",
    "lv_ref_base=lv_airPLS(lv_raw_reference.T,lambda_=lambd,porder=porder,itermax=itermax).reshape(len(lv_raw_reference),1)\n",
    "lv_g_base=lv_airPLS(lv_raw_green.T,lambda_=lambd,porder=porder,itermax=itermax).reshape(len(lv_raw_green),1)\n",
    "lv_r_base=lv_airPLS(lv_raw_red.T,lambda_=lambd,porder=porder,itermax=itermax).reshape(len(lv_raw_red),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the baselines that will be subtracted later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_ref_base, lv_ref_base)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_g_base, lv_g_base)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_r_base, lv_r_base)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*, block=None)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(cp_g_base)\n",
    "plt.plot(lv_g_base)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything checks out! Now subtract baseline and recheck for differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = 0\n",
    "cp_subtracted_reference = cp_reference[remove:] - cp_ref_base[remove:]\n",
    "cp_subtracted_gsignal = cp_signal_green[remove:] - cp_g_base[remove:]\n",
    "cp_subtracted_rsignal = cp_signal_red[remove:] - cp_r_base[remove:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = 0\n",
    "lv_subtracted_reference = lv_reference[remove:] - lv_ref_base[remove:]\n",
    "lv_subtracted_gsignal = lv_signal_green[remove:] - lv_g_base[remove:]\n",
    "lv_subtracted_rsignal = lv_signal_red[remove:] - lv_r_base[remove:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_subtracted_reference, lv_subtracted_reference)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_subtracted_gsignal, lv_subtracted_gsignal)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b} : difference is {a - b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_subtracted_rsignal, lv_subtracted_rsignal)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b} : difference is {a - b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*, block=None)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(cp_subtracted_gsignal)\n",
    "plt.plot(lv_subtracted_gsignal)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything checks out so let's move on to checking if z-scoring the signals are the same for both datasets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_z_reference = (cp_subtracted_reference - np.median(cp_subtracted_reference)) / np.std(cp_subtracted_reference)\n",
    "cp_z_green = (cp_subtracted_gsignal - np.median(cp_subtracted_gsignal)) / np.std(cp_subtracted_gsignal)\n",
    "cp_z_red = (cp_subtracted_rsignal - np.median(cp_subtracted_rsignal)) / np.std(cp_subtracted_rsignal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_z_reference = (lv_subtracted_reference - np.median(lv_subtracted_reference)) / np.std(lv_subtracted_reference)\n",
    "lv_z_green = (lv_subtracted_gsignal - np.median(lv_subtracted_gsignal)) / np.std(lv_subtracted_gsignal)\n",
    "lv_z_red = (lv_subtracted_rsignal - np.median(lv_subtracted_rsignal)) / np.std(lv_subtracted_rsignal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_z_reference, lv_z_reference)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b} : difference is {a - b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_z_green, lv_z_green)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b} : difference is {a - b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_z_red, lv_z_red)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b} : difference is {a - b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*, block=None)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(cp_z_green)\n",
    "plt.plot(lv_z_green)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, still the same. Let's hit it with a lasso regression and calculate dF/F and see whatsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso  # for Lasso regression\n",
    "lin = Lasso(alpha=0.0001, precompute=True, max_iter=1000, positive=True, random_state=9999, selection=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.fit(cp_z_reference, cp_z_green)\n",
    "# lin.fit(cp_z_reference, cp_z_red)\n",
    "cp_z_reference_fitted = lin.predict(cp_z_reference).reshape(len(cp_z_reference), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.fit(lv_z_reference, lv_z_green)\n",
    "# lin.fit(lv_z_reference, lv_z_red)\n",
    "lv_z_reference_fitted = lin.predict(lv_z_reference).reshape(len(lv_z_reference), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_z_reference_fitted, lv_z_reference_fitted)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b} : difference is {a - b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_z_green, lv_z_green)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b} : difference is {a - b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*, block=None)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(cp_z_reference_fitted)\n",
    "plt.plot(lv_z_reference_fitted)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_gzdFF = (cp_z_green - cp_z_reference_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lv_gzdFF = (lv_z_green - lv_z_reference_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i, (a, b) in enumerate(zip(cp_gzdFF, lv_gzdFF)):\n",
    "    if a != b:\n",
    "        print(f\"Difference found at index {i}: {a} != {b} : difference is {a - b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*, block=None)>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(cp_gzdFF)\n",
    "plt.plot(lv_gzdFF)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
